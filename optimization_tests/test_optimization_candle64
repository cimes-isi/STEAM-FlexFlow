#!/bin/bash
#SBATCH --partition=gpu
#SBATCH --gres=gpu:a100:1
#SBATCH --ntasks=1
#SBATCH --cpus-per-task=64
#SBATCH --mem=128GB
#SBATCH --time=10:00:00
module purge
module load gcc/8.3.0
module load python/3.7.6
module load cuda/11.2.0
module load cudnn/8.1.0.77-11.2-cuda
module load cmake/3.16.2
module load openblas/0.3.8
module load pmix/3.1.3
module load openmpi/4.0.2
module load hdf5/1.10.6
module load gdb/9.1
module load zlib/1.2.11
export OMP_NUM_THREADS=64
SECONDS=0
../build/examples/cpp/candle_unosim/candle_unosim -ll:gpu 1 -ll:cpu 1 -ll:zsize 20000 -ll:fsize 39000 -ll:util 4 -dm:memoize --dense-feature-layers 16384-16384-16384-16384-16384-16384-16384-16384-16384-16384-16384-16384-16384-16384-16384-16384 --dense-layers 16384-16384-16384-16384-16384-16384-16384-16384-1 --interface-bandwidth 100 --inter-gpu-bandwidth 100 --gpu-dram-bandwidth 100 --network-latency 1 --net-opt 1  --search-budget 5000 --mfile candle_measures/candle64.json --taskgraph tg.topoopt.100G.candle64.nd4_optimized_64_5000   --batch-size 65536 --nsimnode 64 --enable-propagation --node-degree 4 --simulator-workspace-size 65536 --big-gpu 4 --topology topoopt --no-gpu
duration=$SECONDS
echo "$(($duration / 60)) minutes and $(($duration % 60)) seconds elapsed for optimized candle64 with 64 threads with 5000 search budget"
