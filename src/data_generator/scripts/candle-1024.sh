# to get profile of candle1024
# it produces a file named measure_<batchsize>_<nsimnode>.json
candle_unosim/candle_unosim -ll:gpu 1 -ll:cpu 1 -ll:zsize 20000 -ll:fsize 10000 -ll:util 4 -dm:memoize --dense-feature-layers 16384-16384-16384-16384-16384-16384-16384-16384-16384-16384-16384-16384-16384-16384-16384-16384 --dense-layers 16384-16384-16384-16384-16384-16384-16384-16384-1 --batch-size 1048576 --interface-bandwidth 100 --inter-gpu-bandwidth 100 --gpu-dram-bandwidth 100 --network-latency 1 --net-opt 1 --nsimnode 1024 --search-budget 4000 --measure --enable-propagation --node-degree 4 --simulator-workspace-size 4294967296 --big-gpu 4 
# it find a (near) optimial parallelization for the targe network architecture (topoopt)
# it produces an output file specified by '--taskgraph' option
export OMP_NUM_THREADS=2; time candle_unosim/candle_unosim -ll:gpu 1 -ll:cpu 1 -ll:zsize 20000 -ll:fsize 10000 -ll:util 4 -dm:memoize --dense-feature-layers 16384-16384-16384-16384-16384-16384-16384-16384-16384-16384-16384-16384-16384-16384-16384-16384 --dense-layers 16384-16384-16384-16384-16384-16384-16384-16384-1 --batch-size 1048576 --interface-bandwidth 400 --inter-gpu-bandwidth 256 --gpu-dram-bandwidth 200 --network-latency 1 --net-opt 1 --nsimnode 1024 --search-budget 2 --mfile measures-1024/candle1024.json --taskgraph tg.topoopt.400G.candle1024.nd4.test --enable-propagation --node-degree 4 --simulator-workspace-size 65536 --big-gpu 4 --topology topoopt --no-gpu
